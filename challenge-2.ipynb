{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTUuzCyzRqG"
      },
      "source": [
        "# Challenge 2 - Data Preprocessing\n",
        "\n",
        "Welcome to challenge 2/7! You will be attempting two parts just like in challenge 1 last week i.e., the MCQ section and the code challenge section.\n",
        "\n",
        "Good luck! :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROAjx16L5x5Y"
      },
      "source": [
        "## Section 1: Multiple Choice Questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRALy2NEz0AS"
      },
      "source": [
        "### Q1. What is the primary goal of data preprocessing in machine learning? (1 point)\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1.  To train the model directly.\n",
        "2.  To clean and prepare raw data for better model performance.\n",
        "3.  To increase the size of the dataset.\n",
        "4.  To avoid splitting the dataset into train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFtBxSL40CG9",
        "outputId": "49e0c805-cd5f-4d4b-be20-2cf551c8bc86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1: What is the primary goal of data preprocessing in machine learning?\n",
            "Answer: To clean and prepare raw data for better model performance\n"
          ]
        }
      ],
      "source": [
        "def answer_q1():\n",
        "    \"\"\"\n",
        "    Q1: What is the primary goal of data preprocessing in machine learning?\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"To train the model directly\",\n",
        "        2: \"To clean and prepare raw data for better model performance\",\n",
        "        3: \"To increase the size of the dataset\",\n",
        "        4: \"To avoid splitting the dataset into train and test sets\",\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "\n",
        "print(\n",
        "    f\"Q1: What is the primary goal of data preprocessing in machine learning?\\nAnswer: {answer_q1()}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9BRj9Qv0v9o"
      },
      "source": [
        "### Q2. Which of the following techniques is used to handle missing numerical data? (1 point)\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1. One-hot encoding\n",
        "2. Imputing with mean, median, or mode\n",
        "3. Removing categorical columns\n",
        "4. Detecting outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFto7n3ny7UA",
        "outputId": "2025056d-b701-4a72-89b4-7a459c2828b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2: Which of the following techniques is used to handle missing numerical data?\n",
            "Answer: Imputing with mean, median, or mode\n"
          ]
        }
      ],
      "source": [
        "def answer_q2():\n",
        "    \"\"\"\n",
        "    Q2: Which of the following techniques is used to handle missing numerical data?\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"One-hot encoding\",\n",
        "        2: \"Imputing with mean, median, or mode\",\n",
        "        3: \"Removing categorical columns\",\n",
        "        4: \"Detecting outliers\",\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "\n",
        "print(\n",
        "    f\"Q2: Which of the following techniques is used to handle missing numerical data?\\nAnswer: {answer_q2()}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAYgSO7Z2FTd"
      },
      "source": [
        "### Q3. What does one-hot encoding do? (1 point)\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1. Replaces missing numerical values with zeros.\n",
        "2. Converts numerical columns into categorical columns.\n",
        "3. Converts categorical data into binary columns, one for each category.\n",
        "4. Detects and removes outliers from a dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5SAsK9C2Z8R",
        "outputId": "edd20aeb-bf1e-4fcf-fd84-17c8e39a92a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3: What does one-hot encoding do?\n",
            "Answer: Converts categorical data into binary columns, one for each category\n"
          ]
        }
      ],
      "source": [
        "def answer_q3():\n",
        "    \"\"\"\n",
        "    Q3: What does one-hot encoding do?\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"Replaces missing numerical values with zeros\",\n",
        "        2: \"Converts numerical columns into categorical columns\",\n",
        "        3: \"Converts categorical data into binary columns, one for each category\",\n",
        "        4: \"Detects and removes outliers from a dataset\",\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[3]\n",
        "\n",
        "\n",
        "print(f\"Q3: What does one-hot encoding do?\\nAnswer: {answer_q3()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shVhsUec2zS4"
      },
      "source": [
        "### Q4. Which method can be used to detect outliers in a dataset? (1 point)\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1.  Box plot visualization\n",
        "2.  Calculating the correlation matrix\n",
        "3.  Applying one-hot encoding\n",
        "4.  Normalizing the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS7K8DqW4Hpr",
        "outputId": "56665bdf-af18-4045-b17a-0489035b20cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q4: Which method can be used to detect outliers in a dataset?\n",
            "Answer: Box plot visualization\n"
          ]
        }
      ],
      "source": [
        "def answer_q4():\n",
        "    \"\"\"\n",
        "    Q4: Which method can be used to detect outliers in a dataset?\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"Box plot visualization\",\n",
        "        2: \"Calculating the correlation matrix\",\n",
        "        3: \"Applying one-hot encoding\",\n",
        "        4: \"Normalizing the data\",\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[1]\n",
        "\n",
        "\n",
        "print(\n",
        "    f\"Q4: Which method can be used to detect outliers in a dataset?\\nAnswer: {answer_q4()}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UizfbmVn46j1"
      },
      "source": [
        "### Q5. You are working with a dataset containing a timestamp column (purchase_date). Which of the following feature engineering techniques would help capture temporal patterns effectively for predictive modeling? (2 points)\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1. Extracting the day of the week, month, and hour from purchase_date.\n",
        "2. Converting the purchase_date to a UNIX timestamp and normalizing it.\n",
        "3. Creating features like \"days since last purchase\" for each customer.\n",
        "4. All of the above.\n",
        "5. None of the above.\n",
        "\n",
        "For this question alone, justify your answer briefly by replacing the string value of `why` with your explanation in addition to returning the correct option.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAeIC4Us5Lst",
        "outputId": "f98a3b83-386b-419e-f25a-a438df3c986f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Q5: You are working with a dataset containing a timestamp column (purchase_date).Which of the following feature engineering techniques would help capture temporal patterns effectively for predictive modeling?\n",
            "Answer: ('Converting the purchase_date to a UNIX timestamp and normalizing it', 'Because a single normalized value is much easier for a model to work with than multiple different features')\n"
          ]
        }
      ],
      "source": [
        "def answer_q5():\n",
        "    \"\"\"\n",
        "    Q5: You are working with a dataset containing a timestamp column (purchase_date).\n",
        "    Which of the following feature engineering techniques would help capture temporal\n",
        "    patterns effectively for predictive modeling?\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"Extracting the day of the week, month, and hour from purchase_date\",\n",
        "        2: \"Converting the purchase_date to a UNIX timestamp and normalizing it\",\n",
        "        3: \"Creating features like 'days since last purchase' for each customer\",\n",
        "        4: \"All of the above\",\n",
        "        5: \"None of the above\",\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    # Include your justification below in a line or two\n",
        "    why = \"Because a single normalized value is much easier for a model to work with than multiple different features\"\n",
        "    return options[2], why\n",
        "\n",
        "\n",
        "print(\n",
        "    f\" Q5: You are working with a dataset containing a timestamp column (purchase_date).Which of the following feature engineering techniques would help capture temporal patterns effectively for predictive modeling?\\nAnswer: {answer_q5()}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2tw01le53fJ"
      },
      "source": [
        "---\n",
        "\n",
        "## Section 2: Code challenge (4 points)\n",
        "\n",
        "To pass this section of the weekly challenge, uncomment/fill in code where necessary (marked with a 'TODO:' comment).\n",
        "\n",
        "### 1. House keeping and imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cm3MG7iySn15"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hry_mfD2St36"
      },
      "source": [
        "### 2. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t6L9tk63SxuZ"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    # TODO: Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "f1hXAB3jUgKx",
        "outputId": "741033c1-54fa-4302-e476-e7ca0ec1ecc4"
      },
      "outputs": [],
      "source": [
        "data = load_data(\"titanic.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Explore dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO Display the first few rows of the dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "LIx_rzFPcVf7",
        "outputId": "49126114-f294-41c4-cf2f-35a1686dcad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# TODO: Display the dataset's information\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fill in the code below to return a dataframe that has the total number of missing (null) values per column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def number_missing_values(data):\n",
        "    # TODO: Return the number of missing values in each column\n",
        "    return data.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww-oRhCNS0_6"
      },
      "source": [
        "### 4. Handle Missing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Cannot convert ['S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'Q' 'S' 'C' 'C' 'Q' 'S' 'C' 'S'\n 'C' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'Q' 'S' 'Q' 'Q' 'C' 'S' 'S' 'S' 'C' 'S'\n 'C' 'S' 'S' 'C' 'S' 'S' 'C' nan 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'Q' 'S' 'C' 'S' 'S' 'C' 'S' 'Q' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'C'\n 'Q' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'Q'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'Q' 'S'\n 'Q' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'C' 'S' 'S' 'S' 'S' 'Q' 'C'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'C' 'C' 'S' 'C' 'S' 'Q' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'Q' 'S' 'Q' 'S' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'Q' 'S' 'C' 'C' 'S' 'S' 'C' 'C' 'S' 'S' 'C' 'Q' 'Q' 'S' 'Q' 'S' 'S'\n 'C' 'C' 'C' 'C' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'Q'\n 'S' 'C' 'C' 'S' 'Q' 'S' 'C' 'C' 'Q' 'C' 'C' 'S' 'S' 'C' 'S' 'C' 'S' 'C'\n 'C' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'C' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S'\n 'S' 'S' 'C' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'Q' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S'\n 'C' 'C' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'C' 'S' 'S' 'S' 'C' 'S' 'C'\n 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'Q' 'C' 'S' 'S' 'C' 'C'\n 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'S'\n 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'C' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'Q'\n 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'S'\n 'Q' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'Q'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'S' 'C'\n 'S' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S' 'S' 'Q' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'C' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'C' 'S' 'C' 'S'\n 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'Q' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C'\n 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'Q' 'S' 'S' 'S' 'S' 'C'\n 'S' 'S' 'Q' 'S' 'Q' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'C' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'C'\n 'Q' nan 'C' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'S' 'S'\n 'S' 'C' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'Q'] to numeric",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m     df_processed\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_processed\n\u001b[0;32m---> 41\u001b[0m \u001b[43mpreprocess_final\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# try with train data\u001b[39;00m\n\u001b[1;32m     45\u001b[0m df_train \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36mpreprocess_final\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m median_age \u001b[38;5;241m=\u001b[39m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m     15\u001b[0m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(median_age)\n\u001b[0;32m---> 17\u001b[0m median_embarked \u001b[38;5;241m=\u001b[39m \u001b[43mdf_processed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(median_embarked)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# TODO: drop columns\u001b[39;00m\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/series.py:6559\u001b[0m, in \u001b[0;36mSeries.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6551\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m   6553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6557\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6558\u001b[0m ):\n\u001b[0;32m-> 6559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/generic.py:12431\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  12425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12426\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/ise/github-classroom/ai/challenge-2-darragh0/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert ['S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'Q' 'S' 'C' 'C' 'Q' 'S' 'C' 'S'\n 'C' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'Q' 'S' 'Q' 'Q' 'C' 'S' 'S' 'S' 'C' 'S'\n 'C' 'S' 'S' 'C' 'S' 'S' 'C' nan 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'Q' 'S' 'C' 'S' 'S' 'C' 'S' 'Q' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'C'\n 'Q' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'Q'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'Q' 'S'\n 'Q' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'C' 'S' 'S' 'S' 'S' 'Q' 'C'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'C' 'C' 'S' 'C' 'S' 'Q' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'Q' 'S' 'Q' 'S' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'Q' 'S' 'C' 'C' 'S' 'S' 'C' 'C' 'S' 'S' 'C' 'Q' 'Q' 'S' 'Q' 'S' 'S'\n 'C' 'C' 'C' 'C' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'Q'\n 'S' 'C' 'C' 'S' 'Q' 'S' 'C' 'C' 'Q' 'C' 'C' 'S' 'S' 'C' 'S' 'C' 'S' 'C'\n 'C' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'C' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S'\n 'S' 'S' 'C' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S'\n 'Q' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S'\n 'C' 'C' 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'C' 'S' 'S' 'S' 'C' 'S' 'C'\n 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'Q' 'C' 'S' 'S' 'C' 'C'\n 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'Q' 'S' 'S'\n 'S' 'S' 'C' 'S' 'S' 'C' 'S' 'C' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'Q'\n 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'S'\n 'Q' 'Q' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'S' 'S' 'Q'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'S' 'C'\n 'S' 'S' 'S' 'S' 'S' 'Q' 'Q' 'S' 'S' 'Q' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'Q' 'C' 'S' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'C' 'S' 'S' 'S' 'Q' 'C' 'S' 'C' 'S'\n 'C' 'Q' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'Q' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C'\n 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'Q' 'Q' 'S' 'S' 'S' 'S' 'C'\n 'S' 'S' 'Q' 'S' 'Q' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'C' 'Q' 'S'\n 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S'\n 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'Q' 'S' 'C'\n 'Q' nan 'C' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'C' 'S' 'S' 'C' 'C' 'S' 'S'\n 'S' 'C' 'S' 'C' 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'S'\n 'S' 'S' 'C' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'C' 'C' 'S' 'S' 'S' 'C' 'S' 'S'\n 'S' 'S' 'S' 'Q' 'S' 'S' 'S' 'C' 'Q'] to numeric"
          ]
        }
      ],
      "source": [
        "def preprocess_final(df):\n",
        "    \"\"\"\n",
        "    1) fix missing data (Age, Embarked, etc.)\n",
        "    2) drop unneeded columns (Cabin, Ticket, Name, PassengerId)\n",
        "    3) encode 'Sex', 'Embarked'\n",
        "    4) create at least 1 new feature\n",
        "    5) ensure no NaN in final numeric columns\n",
        "\n",
        "    returns df_processed with no missing values in essential columns\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # TODO: handle missing Age (fill with median?), handle missing Embarked, etc.\n",
        "    median_age = df_processed[\"Age\"].median()\n",
        "    df_processed[\"Age\"] = df_processed[\"Age\"].fillna(median_age)\n",
        "\n",
        "    # TODO: drop columns\n",
        "    drop_cols = [\"Cabin\", \"Ticket\", \"Name\", \"PassengerId\"]\n",
        "    df_processed = df_processed.drop(drop_cols, axis=1)\n",
        "\n",
        "    # TODO: binary encode 'Sex'\n",
        "    df_processed[\"Sex\"] = df_processed[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "\n",
        "    # fill the 2 empty values with the most common value 'S'\n",
        "    df_processed[\"Embarked\"] = df_processed[\"Embarked\"].fillna(\"S\")\n",
        "\n",
        "    # TODO: one-hot encode 'Embarked'\n",
        "    df_processed = pd.get_dummies(df_processed, columns=[\"Embarked\"], drop_first=True)\n",
        "\n",
        "    # TODO: create at least 1 new feature\n",
        "    # e.g. FamilySize = SibSp + Parch + 1\n",
        "    # df_processed['FamilySize'] = ...\n",
        "\n",
        "    # final step: drop or fill any remaining missing\n",
        "    df_processed.dropna(inplace=True)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "\n",
        "# try with train data\n",
        "df_train = load_data(\"titanic.csv\")\n",
        "df_processed = preprocess_final(df_train)\n",
        "print(\"After preprocess_final():\")\n",
        "print(\"Columns:\", df_processed.columns)\n",
        "print(\"Missing Values:\", df_processed.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the dataset's common statistical information after preprocessing\n",
        "df_processed.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaVV4aDxYEUH"
      },
      "source": [
        "### 5. Looking at outliers\n",
        "\n",
        "It is often useful to look at data for outliers. The following function plots histograms for all the numerical data in a dataframe. This will give an idea of the general distribution of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ks_Nl1DZKtQ"
      },
      "outputs": [],
      "source": [
        "def plot_histograms(df, bins=20):\n",
        "    \"\"\"\n",
        "    Plots histograms for all columns in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        bins (int, optional): Number of bins for the histograms. Defaults to 20.\n",
        "    \"\"\"\n",
        "    # Get numeric columns for histogram plotting\n",
        "    numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "    axes = axes.flatten()  # Flatten to iterate easily\n",
        "\n",
        "    # Iterate and plot histograms for each numeric column\n",
        "    for i, col in enumerate(numeric_columns):\n",
        "        axes[i].hist(\n",
        "            df[col], bins=bins\n",
        "        )  # The bins argument should be an integer for number of bins, not column\n",
        "        axes[i].set_title(f\"Histogram of {col}\")\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel(\"Frequency\")\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the histograms for the numerical features of the processed dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "Y28prbvuZ3WC",
        "outputId": "cc70225e-c8ea-450c-8db0-c2cf12982e8c"
      },
      "outputs": [],
      "source": [
        "plot_histograms(df_processed, bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A boxplot gives the general distribution of data in terms of quartile ranges and shows us outliers very clearly. Running the code cell below will show the box plot for the `Age` column grouped by the target column of `Survived`.  \n",
        "This shows us the median age of those who survived and didn't as well as certain data points that seem to be against the norm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed.boxplot(column=\"Age\", by=\"Survived\", grid=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO: SHould the age outliers should be capped or removed from the dataset. Briefly justify.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Your answer here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyJw8z1wTbBd"
      },
      "source": [
        "### 6. Training and testing (not graded)\n",
        "\n",
        "Now that we have our clean and pre-processed data, feel free to run a classifier of choice and see the accuracy you get.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdQ3FZ4dThWY"
      },
      "outputs": [],
      "source": [
        "def train_test(df):\n",
        "    \"\"\"\n",
        "    Trains a classifier model on the input DataFrame.\n",
        "    Returns:\n",
        "        float: Accuracy of the trained model.\n",
        "    \"\"\"\n",
        "    # Optional:\n",
        "    # train and test a classifier model on the pre-processed data\n",
        "    # X, y = df.drop('Survived', axis=1).values, df['Survived'].values\n",
        "    # ...\n",
        "\n",
        "    # return accuracy\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VnXRdEERRxTD",
        "outputId": "8b7b4974-9038-4f61-a191-4a7bddecdfb1"
      },
      "outputs": [],
      "source": [
        "# accuracy = train_test(df_processed)\n",
        "print(f\"Model Accuracy: {100 * accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
